apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  labels:
    app: kafka
spec:
  serviceName: kafka-headless
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: kafka
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: kafka
    spec:
      serviceAccountName: {{ .Values.serviceAccount.name }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      initContainers:
        - name: init-kafka-data
          image: busybox:latest
          command: ["/bin/sh", "-c"]
          args:
            - |
              mkdir -p /kafka/data/logs
              chown -R 1000:1000 /kafka/data
          volumeMounts:
            - name: kafka-data
              mountPath: /kafka/data
          securityContext:
            runAsUser: 0
      containers:
        - name: kafka
          image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          securityContext:
            {{- toYaml .Values.containerSecurityContext | nindent 12 }}
          ports:
            - name: broker
              containerPort: {{ .Values.ports.broker }}
              protocol: TCP
            - name: controller
              containerPort: {{ .Values.ports.controller }}
              protocol: TCP
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: CLUSTER_ID
              valueFrom:
                configMapKeyRef:
                  name: kafka-config
                  key: clusterId
            - name: KAFKA_NODE_ID
              value: "{{`{{ .Pod.Name | replace \"kafka-\" \"\" }}`}}"
            - name: KAFKA_PROCESS_ROLES
              value: "broker,controller"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://0.0.0.0:{{ .Values.ports.broker }},CONTROLLER://0.0.0.0:{{ .Values.ports.controller }}"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://{{`{{ .Pod.Name }}`}}.{{ .Values.cluster.domain }}:{{ .Values.ports.broker }}"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "PLAINTEXT"
            - name: KAFKA_CONTROLLER_LISTENER_NAMES
              value: "CONTROLLER"
            - name: KAFKA_CONTROLLER_QUORUM_VOTERS
              value: "{{ range $i, $e := until (int .Values.replicaCount) }}{{ $i }}@kafka-{{ $i }}.{{ $.Values.cluster.domain }}:{{ $.Values.ports.controller }}{{ if ne $i (sub (int $.Values.replicaCount) 1) }},{{ end }}{{ end }}"
            - name: KAFKA_LOG_DIRS
              value: "/kafka/data"
            - name: KAFKA_LOG4J_OPTS
              value: "-Dlog4j2.configurationFile=file:/kafka/config/log4j2.properties"
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          readinessProbe:
            tcpSocket:
              port: {{ .Values.ports.broker }}
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 6
          livenessProbe:
            tcpSocket:
              port: {{ .Values.ports.broker }}
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 8
          volumeMounts:
            - name: kafka-data
              mountPath: /kafka/data
            - name: kafka-config
              mountPath: /kafka/config
          command: ["/bin/bash", "-c"]
          args:
            - |
              # Copy log4j configuration from ConfigMap
              cp /kafka/config/log4j2.properties /opt/kafka/config/log4j2.properties
              # Format storage if meta.properties does not exist
              if [ ! -f /kafka/data/meta.properties ]; then
                /opt/kafka/bin/kafka-storage.sh format -t $CLUSTER_ID -c /opt/kafka/config/server.properties
              fi
              # Start Kafka server with Confluent overrides
              exec /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties \
                --override process.roles=$KAFKA_PROCESS_ROLES \
                --override node.id=$KAFKA_NODE_ID \
                --override listeners=$KAFKA_LISTENERS \
                --override advertised.listeners=$KAFKA_ADVERTISED_LISTENERS \
                --override listener.security.protocol.map=$KAFKA_LISTENER_SECURITY_PROTOCOL_MAP \
                --override inter.broker.listener.name=$KAFKA_INTER_BROKER_LISTENER_NAME \
                --override controller.listener.names=$KAFKA_CONTROLLER_LISTENER_NAMES \
                --override controller.quorum.voters=$KAFKA_CONTROLLER_QUORUM_VOTERS \
                --override log.dirs=$KAFKA_LOG_DIRS
      volumes:
        - name: kafka-config
          configMap:
            name: kafka-config
      {{- if .Values.persistence.enabled }}
        - name: kafka-data
          persistentVolumeClaim:
            claimName: kafka-pvc
      {{- else }}
        - name: kafka-data
          emptyDir: {}
      {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}