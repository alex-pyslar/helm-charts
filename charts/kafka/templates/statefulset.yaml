apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
spec:
  serviceName: kafka-headless
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 1001
      containers:
        - name: kafka
          image: {{ .Values.image }}
          imagePullPolicy: {{ .Values.imagePullPolicy }}
          ports:
            - containerPort: {{ .Values.port.broker }}
            - containerPort: {{ .Values.port.controller }}
          resources: {{ .Values.resources | toYaml | nindent 10 }}
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: CLUSTER_ID
              value: {{ .Values.clusterId }}
            - name: KAFKA_NODE_ID
              value: "0"
            - name: KAFKA_PROCESS_ROLES
              value: "broker,controller"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://:{{ .Values.port.broker }},CONTROLLER://:{{ .Values.port.controller }}"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://kafka-0.kafka-headless:{{ .Values.port.broker }}"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "PLAINTEXT"
            - name: KAFKA_CONTROLLER_LISTENER_NAMES
              value: "CONTROLLER"
            - name: KAFKA_CONTROLLER_QUORUM_VOTERS
              value: "0@kafka-0.kafka-headless:{{ .Values.port.controller }}"
            - name: KAFKA_LOG_DIRS
              value: "/kafka/data"
            - name: KAFKA_LOG4J_OPTS
              value: "-Dlog4j2.configurationFile=file:/opt/kafka/config/log4j2.properties -Xlog:gc*:file=/kafka/data/logs/kafkaServer-gc.log:time,tags:filecount=10,filesize=100M"
          readinessProbe:
            tcpSocket:
              port: {{ .Values.port.broker }}
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 6
          livenessProbe:
            tcpSocket:
              port: {{ .Values.port.broker }}
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 8
          command: ["/bin/bash", "-c"]
          args:
            - |
              if [ ! -d /kafka/data ]; then
                mkdir -p /kafka/data
                chown -R 1001:1001 /kafka/data
              fi
              if [ ! -d /kafka/data/logs ]; then
                mkdir -p /kafka/data/logs
                chown -R 1001:1001 /kafka/data/logs
              fi
              if [ ! -f /kafka/data/meta.properties ]; then
                /opt/kafka/bin/kafka-storage.sh format -t $CLUSTER_ID -c /opt/kafka/config/kraft/server.properties
              fi
              /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/kraft/server.properties \
                --override process.roles=$KAFKA_PROCESS_ROLES \
                --override node.id=$KAFKA_NODE_ID \
                --override listeners=$KAFKA_LISTENERS \
                --override advertised.listeners=$KAFKA_ADVERTISED_LISTENERS \
                --override listener.security.protocol.map=$KAFKA_LISTENER_SECURITY_PROTOCOL_MAP \
                --override inter.broker.listener.name=$KAFKA_INTER_BROKER_LISTENER_NAME \
                --override controller.listener.names=$KAFKA_CONTROLLER_LISTENER_NAMES \
                --override controller.quorum.voters=$KAFKA_CONTROLLER_QUORUM_VOTERS \
                --override log.dirs=$KAFKA_LOG_DIRS
          volumeMounts:
            - name: kafka
              mountPath: /kafka/data
              subPath: kafka
      volumes:
        - name: kafka
          persistentVolumeClaim:
            claimName: kafka