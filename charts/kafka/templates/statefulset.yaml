apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
spec:
  serviceName: kafka-headless
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 1001
      containers:
        - name: kafka
          image: {{ .Values.image }}
          imagePullPolicy: {{ .Values.imagePullPolicy }}
          ports:
            - containerPort: {{ .Values.port.broker }}
            - containerPort: {{ .Values.port.controller }}
          resources: {{ .Values.resources | toYaml | nindent 10 }}
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: CLUSTER_ID
              value: {{ .Values.clusterId }}
            - name: KAFKA_NODE_ID
              value: "0"
            - name: KAFKA_PROCESS_ROLES
              value: "broker,controller"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://:{{ .Values.port.broker }},CONTROLLER://:{{ .Values.port.controller }}"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://kafka-0.kafka-headless:{{ .Values.port.broker }}"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "PLAINTEXT"
            - name: KAFKA_CONTROLLER_LISTENER_NAMES
              value: "CONTROLLER"
            - name: KAFKA_CONTROLLER_QUORUM_VOTERS
              value: "0@kafka-0.kafka-headless:{{ .Values.port.controller }}"
            - name: KAFKA_LOG_DIRS
              value: "/kafka/data"
            - name: KAFKA_LOG4J_OPTS
              value: "-Dlog4j2.configurationFile=file:/kafka/data/log4j2.properties"
            - name: KAFKA_OPTS
              value: "-Djava.util.logging.config.file=/kafka/data/logging.properties"
          readinessProbe:
            tcpSocket:
              port: {{ .Values.port.broker }}
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 6
          livenessProbe:
            tcpSocket:
              port: {{ .Values.port.broker }}
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 8
          command: ["/bin/bash", "-c"]
          args:
            - |
              if [ ! -d /kafka/data ]; then
                mkdir -p /kafka/data
                chown -R 1001:1001 /kafka/data
              fi
              if [ ! -d /kafka/data/logs ]; then
                mkdir -p /kafka/data/logs
                chown -R 1001:1001 /kafka/data/logs
              fi
              if [ ! -f /kafka/data/log4j2.properties ]; then
                cat > /kafka/data/log4j2.properties <<EOF
              appenders=rolling
              appender.rolling.name=ROLLING
              appender.rolling.type=RollingFile
              appender.rolling.fileName=/kafka/data/logs/kafka.log
              appender.rolling.filePattern=/kafka/data/logs/kafka-%d{yyyy-MM-dd}.log
              appender.rolling.layout.type=PatternLayout
              appender.rolling.layout.pattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n
              appender.rolling.policies.type=Policies
              appender.rolling.policies.time.type=TimeBasedTriggeringPolicy
              appender.rolling.policies.time.interval=1
              appender.rolling.policies.time.modulate=true
              appender.rolling.strategy.type=DefaultRolloverStrategy
              appender.rolling.strategy.max=10
              loggers=rolling
              logger.rolling.name=kafka
              logger.rolling.level=info
              logger.rolling.additivity=false
              logger.rolling.appenderRef.rolling.ref=ROLLING
              rootLogger.level=info
              rootLogger.appenderRef.rolling.ref=ROLLING
              EOF
              chown 1001:1001 /kafka/data/log4j2.properties
              fi
              if [ ! -f /kafka/data/logging.properties ]; then
                cat > /kafka/data/logging.properties <<EOF
              handlers=java.util.logging.FileHandler
              java.util.logging.FileHandler.pattern=/kafka/data/logs/kafkaServer-gc.log
              java.util.logging.FileHandler.limit=104857600
              java.util.logging.FileHandler.count=10
              java.util.logging.FileHandler.formatter=java.util.logging.SimpleFormatter
              java.util.logging.SimpleFormatter.format=%1$tY-%1$tm-%1$td %1$tH:%1$tM:%1$tS %4$s %2$s %5$s%6$s%n
              EOF
              chown 1001:1001 /kafka/data/logging.properties
              fi
              if [ ! -f /kafka/data/meta.properties ]; then
                cp /opt/kafka/config/kraft/server.properties /kafka/data/server.properties
                echo "log.dirs=/kafka/data" >> /kafka/data/server.properties
                echo "log4j.appender.kafkaAppender.File=/kafka/data/logs/kafka.log" >> /kafka/data/server.properties
                chown 1001:1001 /kafka/data/server.properties
                /opt/kafka/bin/kafka-storage.sh format -t $CLUSTER_ID -c /kafka/data/server.properties
              fi
              /opt/kafka/bin/kafka-server-start.sh /kafka/data/server.properties \
              --override process.roles=$KAFKA_PROCESS_ROLES \
              --override node.id=$KAFKA_NODE_ID \
              --override listeners=$KAFKA_LISTENERS \
              --override advertised.listeners=$KAFKA_ADVERTISED_LISTENERS \
              --override listener.security.protocol.map=$KAFKA_LISTENER_SECURITY_PROTOCOL_MAP \
              --override inter.broker.listener.name=$KAFKA_INTER_BROKER_LISTENER_NAME \
              --override controller.listener.names=$KAFKA_CONTROLLER_LISTENER_NAMES \
              --override controller.quorum.voters=$KAFKA_CONTROLLER_QUORUM_VOTERS \
              --override log.dirs=$KAFKA_LOG_DIRS
          volumeMounts:
            - name: kafka
              mountPath: /kafka/data
      volumes:
        - name: kafka
          persistentVolumeClaim:
            claimName: kafka